# DS_notes-prac

## chap 1
information in memory 
- no exercises required for this chap
- dove into the basics of how we store data in our computer memory
- variables:
    - names representing the location of a piece of data in the computers memory
    - we can visualize memory as a long coloumn of bins 
    - double precision floating point number would require more memory, therefore more bins. ex, 12.34
    - boolean types, true or false
- composite data structures:
    - struct or an object, which gather multiple individual variables into a single group (list, array, dictionary)
    - good ex, buisness cards
    - we use the syntax composite.field to indicate accessing a particular field of a composite data structure (latest_record.name = "sublime blend")
- arrays
     - provide a simple mechanism for storing multiple values in adjacent or indexable bins (arr[3] = 4902)
     - the rows of lockers lining a school hallway
     - values inside the arrays are known as elements
     - arrays aren't like books on a shelf, you have to remove a book and place it somewhere else to replace that book 
        - to do this you can assign books to temporary values, move the elements inside, and then replace the element to the new open indexed space
- insertion sort
    - type of algo to sort values in an array
    - works by sorting a subset of the array and expanding this sorted range until the entire array is in order
    - coffee expiration data: compare the first two, from left to right, shortest expiration date to longest, and then uses that subset to file in the 3rd index into its rightful place. 
- strings
    - ordered lists, special kind of arrays
    - when we display a string on the screen, we are effectively iterating through each of its characters and displaying them one at a time
- why this matters 
    - staples of programming classes. 
    - very foundation of comp pro and data structures
    - concepts provide the baseline aganist which to evaluate dynamic data structures and thier impact on algorythms. 
    - dynamic data structure can offer trade-offs amoung efficency, flexibility and complexity. 

## chap 2 
binary search 
- checks the sorted list for a target value by repeated dividing the list in half, determining which of the two would contain the target value, discarding the other half
- linear scan 
    - providing a baseline for comparison for binary search 
    - works by testing each value in our list for our specific value
    - a single while loop iterates over each item in the array, the internal if statement compares that element to the target, as soon as we come across the element, it returns the element, if not, it will return -1 
    - brute force test garuenteed to find the itme of interest 
    - ex, going down the line of students asking each student their name till you find the one youre looking for 
- binary search algo
    - finds target value v in a sorted list, and only works on sorted data
    - algo can we written to work with data in either increasing or decreasing order
    - similar to logic when avoiding ice cream isle when we know we dont need ice cream. once we know an item isnt in a certain area, we can rule out that entire set of items 
    - searches the space between 2 bounds, the IndexHigh and the IndexLow, with IndexMid being the center of those two
        - IndexMid = Floor((IndexHigh + IndexLow) / 2)
    - we continue to cut the list in half until our value is found. 
    - binary search waits until the midpoint lands to our target value, because our search will only check the midpoint against out target 
- absent values 
    - if a value is not in the list, returns specified value in the algo
- implementing binary search 
    - implement binary search with a simple while loop
    - compute the mid point 
    - check the midpoint value aganist the target, if its a match we found our target
    - if the value is too high we adjsut our upper bounds 
- adapting binary search 
    - applying to books on a shelf, names in a phone book, clothing rack ordered by size 
    - instead of going value by value, binary search allows for better precision 
    - bisection search uses it to find the zero of a function, or the value of x such that f(x) = 0
- runtime
    - often analyze the runtime of an algo in terms of its average worse-case performance as the size of the data N grows
    - comp sci often use big O notation to more formally capture those concepts. 
    - we consider the same two aspects throughout for each algo
        - avergae case runtime of an algo as the size of the data grows 
        - worst case runtime of an algo as the size of the data grows
    - the benefit of needing only a longarithmic number of comparisons will far outwigh additional per steps costs

## chap 3
dynamic data structures
- dds
    - alter their structure as the data changes 
    - lie at the heart of almost every computer program in the world and are the foundation of some of the most exciting, interesting, and powerful algos in cs 
- the previous data structures are like parking lots, cant change once created. 
- limitations of arrays 
    - their size and layout in memory are fixed at the time of creation 
    - array: simple static array, cannot grow with the data
    - if we want to extend the array, we have to make a bigger array to then copy and place the exisitng set of data into, and then add the new element at the end 
    - array doubling: dulicating the array and doubling the size, ex. 20 slots for data, 18 peices of data, add in 4 pieces of data, double the slots for data to 40. now every time we add data, although it might not fill up the slots, we double the entire thing. as it grows, the doubleing may become less frequent, yet, we still are taking up large sums of memory because of all the unfilled slots. 
- pointers and references 
    - a pointer is a varibale that stores only the addresses in the computers memory
    - ex. say there are just way too many folders inside a cabniet drawer, and you need a way to make sure the drawer stays organized and neat. you decide to take a folder out and leave a not that says "the folder is now at *this location*" that note that you have left is the pointer. 
- linked list
    - simplest ex of dynamic data structures
    - used for storing multiple values 
    - composed of a chain of nodes linked together by pointers
    - a basic node in a linked list is a composite data structure containing two parts, a value(of any type) and a pointer, pointing to the next node in the list
    - slash at the end of a linked list is the end, the head is the begining
    - these linked lists pay attention to their relative order
    - ex. waiting in line in a coffee shop. each person has their name, and they point to the person in front of them, they could be all over the parking lot and seating areas, but as long as they know that the person in front of them is next in line, then they are apart of the linked list. 
    - our list can even be scattered accross the computers memory
    - traversing a linkest list requires moving from one node to the next along the chain of pointers 
    - linked in have a higher computing overhead than arrays 
- operations on linked lists
    - inserting a new value into a linked list requires placing the new values pointer to the space infront of the value, and then placing the space behind its pointer to the new value 
        - ex. x -> y. want to insert n inbetween. n -> y, then x -> n. end with x -> n -> y
        - if we place x's pointer first, we lose the data on where y resides 
    - deleting a value from a linked list
        - all we need to do is delete that node, and adjust the previous nodes pointer to the value ahead of the deleted one. 
    - the strength of the linked list is that they allow us to insert or remove elements without shifting those elements around in the computers memory
- doubly linked lists
    - includes backwards and forwards pointers
    - for algos that need to iterate lists in both directions
    - updating the appropriate nodes previous pointers in addition to their next pointers require additional logic
- arrays and linked lists of items 
    - say you want to make a rsvp list for a party where guests can also include their name and music preferences, and want to make sure their is enough room for all of their characters but not limit it to a number, because what is someone want to type more than the character limit? 
    - this is where we would combine arrays and pointers into one. 
        - each bin in the array stores one pointer to the data of a string somewhere else in the in the memory
        - this allows us to allocate as much space needed for each entry, not taking up more where we dont need to 
        - this allows us to fill the array with fixed size pointers, pointing to larger sets of data
- why this matters
    - linked lists and arryas are only the simplest example of how we can trade off among complextivity, efficentcy, and flexibility in our data structures.
    - a single fixed-size array bin can point to complex data records or strings of different lengths
    
## chap 4
stacks and queues 
- 2 data structures that retrieve stored data based on inserted order 
    - stacks : most recently sorted
    - queues : returns the oldest
- queues enable breadth first search, shallowly explores adjacent paths before digging deeper, this change can dramatically impoact real world behavior 
- stacks 
    - LIFO, last in first out 
    - implement with either arrays or linked lists 
    - when we retireve an element, it is pushed to the array, and now that last element is the top of the array. 
    - must be careful when pushing a lot of elemetns to arrays, if we run out of space, we might expand the array with a technique called array doubling
        - implement an algo to check if there is room to push the element, if there is not, the array doubles, but if there is than the element is pushed
    - since we are only adding or removing items from the end of the array, we dont need to shift around any other elements 
    - as long as there is suffiencent room, we can perform + and - at a constant cost 
        - whether we have 10 elements or 10000, adding or removing an element requires the same number of operations. 
    - alternatively we can implement stacks as linked lists. 
        - the code for pushing starts by creating a new linked list node, then it inserts this node into the front of the list by updating the new nodes next pointer and the stacks head pointer (similar to previous chapter)
        - we are no longer setting a single array value and incrementing an index, the tradeoff is allowing us to have more flexiblility, linked lists can grow and shrink with the data. we no longer have to worry about filling up our array or paying the addtional costs to increase the arrays size
- queues 
    - FIFO, first in first out 
        - similar to a queue in a coffee shop 
    - includes two opertations 
        - Enqueue : adds a new element to the queue, the back
        - Dequeue : takes out the oldest element in the queue, the front
    - preserve the order in which they are added 
    - queues as arrays 
        - to perfrom we track two indices, the first and last element in the queue
        - when we dequeue an element, we move the top to the next place in the array, from [0] to [1], and so on, so when we enqueue, the back would go from say indice [3] to [4].
            - however this can causes issues with a block of empty space in the front of the array, we can solve this with wrapping, wrapping queues allows for less space to be allocated to the growing list. 
    - queues as linked lists 
        - better to implement queues as a linked list or a doubled linked list. 
        - is similiar to the linked list we used for the stack, each element in the queue links to the elemtn immediately behind it. allowing us to traverse the next pointers from the front of the queue to the back
        - allows us to traverse the next pointers from the front of the queue to the back
        - both pointers need to be updated because otherwise they wouldnt be pointing to the valid nodes. 
        - both the enqueue and dequeue operations require a constant number of operations, regaurdless of the size of the queue. 
- the important of order 
    - queues work best when we need our storage to preserve the ordering of insertions. 
    - we use stacks when we want to process the most recent items first 
- depth-first search 
    - an algorithm that continues exploring, deeper and deeper, along a single path until it hits a dead end. 
    - the algo then backs up to the last branching point and check the other options. its maintains a list of furute states to explore using a stack, always choosing the most recently inserted option to try next. 
- breadth-first search 
    - uses similar logic to that of depth-first search to explore topics, but stores future states with a queue. 
    - instead of following those topics further, we take the next item from the front of the queue, and explore the final link from the intial page. 
    - instead of deeply exploring each thread before returning to previous ones, we explore along the frontier of topics, prioritizing breadth over depth. 
    - ideal for people who dont want to let old topics linger and prefer to corss them off before moving onto new topics 
- why this matters
    - both stacks and queues store objects 
    - however, the way they handle the data, and specifically the order in whcih they return the data, gives they similar data structures radically different behaviors 